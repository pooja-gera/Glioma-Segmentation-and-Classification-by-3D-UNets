{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGG_image_paths = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/HGG'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname,filename)\n",
    "        HGG_image_paths.append(file_path)\n",
    "        #print(os.path.join(file_path))\n",
    "print(len(HGG_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGG_image_paths = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/LGG'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname,filename)\n",
    "        LGG_image_paths.append(file_path)\n",
    "        #print(os.path.join(file_path))\n",
    "print(len(LGG_image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "There are 46 images in the HGG category and 48 images in the LGG category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_npy = '/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/HGG/masked_img_denoised_image_0.npy'\n",
    "data_npy = np.load(file_path_npy)\n",
    "data_npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = int(np.ceil(np.sqrt(data_npy.shape[2])))\n",
    "num_cols = int(np.ceil(data_npy.shape[2] / num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/HGG_slices',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/LGG_slices',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/HGG'\n",
    "output_dir = '/kaggle/working/HGG_slices'\n",
    "\n",
    "# Iterate over all .npy files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Load the 3D numpy array from the file\n",
    "        path = os.path.join(input_dir, filename)\n",
    "        #print(path)\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Create a new subdirectory for this image\n",
    "        image_dir = os.path.join(output_dir, os.path.splitext(filename)[0])\n",
    "        #print(image_dir)\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # Save each 2D slice of the 3D numpy array as a separate PNG file\n",
    "        for i in range(data.shape[2]):\n",
    "            slice_path = os.path.join(image_dir, f'slice_{i:03d}.png')\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            plt.imsave(slice_path, data[:, :, i], cmap='gray')\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/LGG'\n",
    "output_dir = '/kaggle/working/LGG_slices'\n",
    "\n",
    "# Iterate over all .npy files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Load the 3D numpy array from the file\n",
    "        path = os.path.join(input_dir, filename)\n",
    "        #print(path)\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Create a new subdirectory for this image\n",
    "        image_dir = os.path.join(output_dir, os.path.splitext(filename)[0])\n",
    "        #print(image_dir)\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # Save each 2D slice of the 3D numpy array as a separate PNG file\n",
    "        for i in range(data.shape[2]):\n",
    "            slice_path = os.path.join(image_dir, f'slice_{i:03d}.png')\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            plt.imsave(slice_path, data[:, :, i], cmap='gray')\n",
    "            plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
