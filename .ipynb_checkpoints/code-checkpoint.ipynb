{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrHjGU8tQ09l"
   },
   "source": [
    "# **Preprocessing: Converting the .nii files to numpy (npy) files of the Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0_PRhE8mWXZ"
   },
   "source": [
    "### **1. Processing a Single Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtOl1vsHK_lG"
   },
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from tifffile import imsave\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bem9MZWL7nJ"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xz4m5mYXMA8U"
   },
   "outputs": [],
   "source": [
    "hgg_dataset_path = '/content/drive/MyDrive/Brain Tumor Major Project/Dataset/HGG/'\n",
    "lgg_dataset_path = '/content/drive/MyDrive/Brain Tumor Major Project/Dataset/LGG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mFGpzuHX2b6",
    "outputId": "926077bb-0351-49f6-c9bb-60ed7495be22"
   },
   "outputs": [],
   "source": [
    "test_image_flair=nib.load(hgg_dataset_path + '1/BraTS19_2013_2_1_flair.nii').get_fdata()\n",
    "print(test_image_flair.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmB02EtMYD5R",
    "outputId": "77557c45-da54-4e2e-af7d-e5defc257723"
   },
   "outputs": [],
   "source": [
    "test_image_flair=scaler.fit_transform(test_image_flair.reshape(-1, test_image_flair.shape[-1])).reshape(test_image_flair.shape)\n",
    "print(test_image_flair.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP0E6lp5YIUa",
    "outputId": "53e52f57-e490-493f-e4ab-4e2b61e52283"
   },
   "outputs": [],
   "source": [
    "test_mask=nib.load(hgg_dataset_path + '1/BraTS19_2013_2_1_seg.nii').get_fdata()\n",
    "test_mask=test_mask.astype(np.uint8)\n",
    "\n",
    "print(np.unique(test_mask))  #0, 1, 2, 4 (Need to reencode to 0, 1, 2, 3)\n",
    "test_mask[test_mask==4] = 3  #Reassign mask values 4 to 3\n",
    "print(np.unique(test_mask)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SHdocPoXnch",
    "outputId": "58969813-b522-4fa5-bc1c-e8f59350c9e8"
   },
   "outputs": [],
   "source": [
    "test_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "TWkpWwXHYf8q",
    "outputId": "ada531ba-a725-4d55-f080-3bf701e7e36f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_image_flair[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9U8LMUTYkx2"
   },
   "outputs": [],
   "source": [
    "test_image_flair=test_image_flair[56:184, 56:184, 13:141] #Crop to 128x128x128x4\n",
    "test_mask = test_mask[56:184, 56:184, 13:141]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAUDSNMXpSjc"
   },
   "source": [
    "### **2. Converting all the .nii files of the dataset to numpy (npy) files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8__0V4_w0rLr"
   },
   "outputs": [],
   "source": [
    "hgg_dataset_path = '/content/drive/MyDrive/Brain Tumor Major Project/Dataset/HGG/'\n",
    "lgg_dataset_path = '/content/drive/MyDrive/Brain Tumor Major Project/Dataset/LGG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPafT4mhaBg7"
   },
   "outputs": [],
   "source": [
    "hgg_flair_list = sorted(glob.glob(hgg_dataset_path+'*/*flair.nii'))\n",
    "hgg_mask_list = sorted(glob.glob(hgg_dataset_path+'*/*seg.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6_e2QUQn1ey"
   },
   "outputs": [],
   "source": [
    "lgg_flair_list = sorted(glob.glob(lgg_dataset_path+'*/*flair.nii'))\n",
    "lgg_mask_list = sorted(glob.glob(lgg_dataset_path+'*/*seg.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO8wgU99Ku48"
   },
   "outputs": [],
   "source": [
    "for img in range(len(hgg_flair_list)):\n",
    "  temp_image_flair=nib.load(hgg_flair_list[img]).get_fdata()\n",
    "  temp_image_flair=scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "      \n",
    "  temp_mask=nib.load(hgg_mask_list[img]).get_fdata()\n",
    "  temp_mask=temp_mask.astype(np.uint8)\n",
    "  temp_mask[temp_mask==4] = 3  \n",
    "\n",
    "  temp_image_flair=temp_image_flair[56:184, 56:184, 13:141]\n",
    "  temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "\n",
    "  val, counts = np.unique(temp_mask, return_counts=True)\n",
    "    \n",
    "  if (1 - (counts[0]/counts.sum())) > 0.01:  #At least 1% useful volume with labels that are not 0\n",
    "      print(\"Save Me \",img)\n",
    "      temp_mask= to_categorical(temp_mask, num_classes=4)\n",
    "      np.save('/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/HGG/Image/image_'+str(img)+'.npy', temp_image_flair)\n",
    "      # np.save('/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/HGG/Mask/mask_'+str(img+50)+'.npy', temp_mask)\n",
    "      \n",
    "  else:\n",
    "      print(\"I am useless\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lkadeiwUUQi"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "b = np.load('/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/LGG/Image/image_50.npy')\n",
    "c = np.load('/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/LGG/Mask/mask_50.npy')\n",
    "c = np.argmax(c, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "POoSAhyGUdm8",
    "outputId": "dc954b78-aa88-4ef9-fbb2-971a57f13b9c"
   },
   "outputs": [],
   "source": [
    "n_slice=random.randint(0, c.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(b[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(232)\n",
    "plt.imshow(c[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv4Ho4goQ5q3"
   },
   "source": [
    "# **Denoising the Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wHe8MY5zyv4"
   },
   "source": [
    "### **1. Denoising MRI Images using NLM Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VT_VmQ3_EGqN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, img_as_float\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim,mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tedq0h_ValZf"
   },
   "outputs": [],
   "source": [
    "hgg_img_source_dir = \"/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/HGG/Image/\"\n",
    "hgg_img_source_list=os.listdir(hgg_img_source_dir)\n",
    "lgg_img_source_dir = \"/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/LGG/Image/\"\n",
    "lgg_img_source_list=os.listdir(lgg_img_source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KoINWpgb_cb"
   },
   "outputs": [],
   "source": [
    "hgg_img_destination_dir = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised_Dataset /HGG/'\n",
    "lgg_img_destination_dir = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised_Dataset /LGG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tcr7hx7pT6rE"
   },
   "outputs": [],
   "source": [
    "def denoise_img(img_source_dir,img_list,img_destination_dir):\n",
    "  value_psnr=[]\n",
    "  value_mse=[]\n",
    "  for i in range(len(img_list)):\n",
    "    print(i)\n",
    "    original_img = np.load(img_source_dir+img_list[i])\n",
    "    sigma_est = np.mean(estimate_sigma(original_img, multichannel=True))\n",
    "    if np.isnan(sigma_est):\n",
    "      sigma_est=0.003\n",
    "    denoise_img = denoise_nl_means(original_img, h=0.77 * sigma_est, fast_mode=True,\n",
    "                                patch_size=5, patch_distance=3, multichannel=True)\n",
    "    \n",
    "    value_psnr.append(psnr(original_img, denoise_img))\n",
    "    value_mse.append(mse(original_img, denoise_img))\n",
    "\n",
    "    print(psnr(original_img, denoise_img), mse(original_img, denoise_img))\n",
    "\n",
    "  df = pd.DataFrame(list(zip(img_list, value_psnr,value_mse)),columns =['Image Name', 'PSNR', 'MSE'])\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H43_Yc6GeFmV"
   },
   "outputs": [],
   "source": [
    "hgg_denoise_evaluate = denoise_img(hgg_img_source_dir, hgg_img_source_list, hgg_img_destination_dir)\n",
    "# lgg_denoise_evaluate = denoise_img(lgg_img_source_dir, lgg_img_source_list, lgg_img_destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "j2NkGBlZguIB",
    "outputId": "e3eb9deb-aae8-4dfb-cafe-cdd3d6a37cc4"
   },
   "outputs": [],
   "source": [
    "hgg_denoise_evaluate.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "Xv40BNBPis-6",
    "outputId": "02cc3e57-f93c-4441-bc94-547f3f3808d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req = (hgg_denoise_evaluate['PSNR'] > 85) & (hgg_denoise_evaluate['PSNR'] < 100)\n",
    "result = hgg_denoise_evaluate[req]\n",
    "result = result.drop('MSE', axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfj3ohY5s9ee"
   },
   "outputs": [],
   "source": [
    "result.to_csv('psnr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdX1H_c2fNtK",
    "outputId": "ff677478-cf3f-4f92-94c9-99a33b4be0d8"
   },
   "outputs": [],
   "source": [
    "print(\"The mean value of PSNR of HGG MRI Images: \", hgg_denoise_evaluate.loc[:, 'PSNR'].mean())\n",
    "print(\"The mean value of MSE of HGG MRI Images: \", hgg_denoise_evaluate.loc[:, 'MSE'].mean())\n",
    "print()\n",
    "print(\"The mean value of PSNR of LGG MRI Images: \", lgg_denoise_evaluate.loc[:, 'PSNR'].mean())\n",
    "print(\"The mean value of MSE of LGG MRI Images: \", lgg_denoise_evaluate.loc[:, 'MSE'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbUmSw1MiQEw"
   },
   "source": [
    "### **2. Saving the Denoised Images Evaluation Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJWfI6f0iYBv"
   },
   "outputs": [],
   "source": [
    "hgg_denoise_evaluate.to_csv('/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised_Dataset/hgg_denoise_evaluate.csv')\n",
    "lgg_denoise_evaluate.to_csv('/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised_Dataset/lgg_denoise_evaluate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9SbYAwlQ9uz"
   },
   "source": [
    "# **Semantic Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11_ReUQmOHs"
   },
   "source": [
    "### **1. Creating a Custom Data Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPFypR3Gd0G0"
   },
   "outputs": [],
   "source": [
    "!pip install segmentation_models_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iboz1lbFHlnW",
    "outputId": "70f8b512-83f5-4abb-e904-c77e0be3d4f9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import segmentation_models_3D as sm\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D6DWjXtBMYr"
   },
   "outputs": [],
   "source": [
    "def load_img(img_dir, img_list):\n",
    "    images=[]\n",
    "    for i, image_name in enumerate(img_list):    \n",
    "        if (image_name.split('.')[1] == 'npy'):\n",
    "            \n",
    "            image = np.load(img_dir+image_name)\n",
    "                      \n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    \n",
    "    return(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3agMtGsLi6oj"
   },
   "outputs": [],
   "source": [
    "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
    "\n",
    "    L = len(img_list)\n",
    "\n",
    "    #keras needs the generator infinite, so we will use while true  \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "                       \n",
    "            X = load_img(img_dir, img_list[batch_start:limit])\n",
    "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
    "\n",
    "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naZzAr4ZiZ0n"
   },
   "source": [
    "### **2. Testing the Data Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvXPWMlli8_S"
   },
   "outputs": [],
   "source": [
    "# hgg\n",
    "hgg_img_dir = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised Image Dataset/HGG/'\n",
    "hgg_mask_dir = \"/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/HGG/Mask/\"\n",
    "hgg_img_list=os.listdir(hgg_img_dir)\n",
    "hgg_mask_list = os.listdir(hgg_mask_dir)\n",
    "\n",
    "# lgg\n",
    "lgg_img_dir = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised Image Dataset/LGG/'\n",
    "lgg_mask_dir = \"/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/LGG/Mask/\"\n",
    "lgg_img_list=os.listdir(lgg_img_dir)\n",
    "lgg_mask_list = os.listdir(lgg_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujmeNCGWjU8W"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "hgg_img_datagen = imageLoader(lgg_img_dir, lgg_img_list, \n",
    "                                lgg_mask_dir, lgg_mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EEG2_vjjbx3"
   },
   "outputs": [],
   "source": [
    "img, msk = hgg_img_datagen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "EqNgF-mwjfsN",
    "outputId": "b5a64162-931f-402a-edf4-31f92b3baa65",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_num = random.randint(0,img.shape[0]-1)\n",
    "test_img=img[img_num]\n",
    "test_mask=msk[img_num]\n",
    "test_mask=np.argmax(test_mask, axis=3)\n",
    "\n",
    "# t = test_img + np.logical_not(test_mask[:,:,:,0])\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "# plt.subplot(223)\n",
    "# plt.imshow(t[:,:,n_slice],cmap='gray')\n",
    "# plt.title('imposed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DB5F2vIijiq"
   },
   "source": [
    "### **3. Modeling for Semantic Segmentation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA5y6NDsGY0g"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "hgg_img_datagen = imageLoader(hgg_img_dir, hgg_img_list, \n",
    "                                hgg_mask_dir, hgg_mask_list, batch_size)\n",
    "\n",
    "lgg_img_datagen = imageLoader(lgg_img_dir, lgg_img_list, \n",
    "                                lgg_mask_dir, lgg_mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RVDkBH2GmAX"
   },
   "outputs": [],
   "source": [
    "#Defining loss, metrics and optimizer to be used for training\n",
    "wt0, wt1, wt2, wt3 = 0.25,0.25,0.25,0.25\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nG4tA2tEIEEo"
   },
   "outputs": [],
   "source": [
    "kernel_initializer =  'he_uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_c4BCApHUjk"
   },
   "outputs": [],
   "source": [
    "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)\n",
    "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    #compile model outside of this function to make it flexible. \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEuk32qFIYUv",
    "outputId": "e53cdd20-ecaf-4932-cb99-07479b377dca",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = simple_unet_model(IMG_HEIGHT=128, \n",
    "                          IMG_WIDTH=128, \n",
    "                          IMG_DEPTH=128, \n",
    "                          IMG_CHANNELS=1, \n",
    "                          num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwulpXWIIhsL",
    "outputId": "b0229f8d-9e95-4209-f324-ec4e4f317d96"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n",
    "\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsHnz3ucIvc4"
   },
   "outputs": [],
   "source": [
    "hgg_steps_per_epoch = len(hgg_img_list)//batch_size\n",
    "lgg_steps_per_epoch = len(lgg_img_list)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGkpsG8FIkYl"
   },
   "outputs": [],
   "source": [
    "history=model.fit(hgg_img_datagen,\n",
    "          steps_per_epoch=hgg_steps_per_epoch,\n",
    "          epochs=100,\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmMcagSUSe3y"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/hgg_segmentation_denoised.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Testing the Results of the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bXYgMwcjP40",
    "outputId": "09b7f117-1578-42b9-f0f8-39216981e305",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing out the Trained Model\n",
    "img_num = 51\n",
    "\n",
    "test_img = np.load(\"/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised_Dataset/LGG/denoised_image_\"+str(img_num)+\".npy\")\n",
    "\n",
    "test_mask = np.load(\"/content/drive/MyDrive/Brain Tumor Major Project/Numpy Dataset/LGG/Mask/mask_\"+str(img_num)+\".npy\")\n",
    "# test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "test_img_input = np.expand_dims(test_img, axis=0)\n",
    "test_prediction = model.predict(test_img_input)\n",
    "test_prediction = test_prediction[0]\n",
    "# test_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]\n",
    "\n",
    "print(test_prediction.shape)\n",
    "\n",
    "# print(test_prediction_argmax.shape)\n",
    "# print(test_mask_argmax.shape)\n",
    "# print(np.unique(test_prediction_argmax))\n",
    "\n",
    "\n",
    "#Plotting individual slices from test predictions for verification\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "#n_slice=random.randint(0, test_prediction_argmax.shape[2])\n",
    "n_slice = 64\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,n_slice], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_mask[:,:,n_slice,0])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction[:,:, n_slice,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DB7gGZq8ypSs"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "iou_score = []\n",
    "f1_Score = []\n",
    "hd_score = []\n",
    "for i in range(len(lgg_mask_list)):\n",
    "  print(i)\n",
    "  test_img = np.load(lgg_img_dir+lgg_img_list[i])\n",
    "  test_mask = np.load(lgg_mask_dir+lgg_mask_list[i])\n",
    "  # test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "  test_img_input = np.expand_dims(test_img, axis=0)\n",
    "  test_prediction = model.predict(test_img_input)\n",
    "  test_prediction = test_prediction[0]\n",
    "  test_prediction_argmax = np.argmax(test_prediction, axis=3)\n",
    "\n",
    "  test_mask_argmax = np.argmax(test_mask, axis=3)\n",
    "\n",
    "  n_classes = 4\n",
    "  IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "  IOU_keras.update_state(test_prediction_argmax, test_mask_argmax)\n",
    "  \n",
    "  f1 = f1_score(test_mask_argmax.ravel(), test_prediction_argmax.ravel(), average=\"weighted\")\n",
    "  # hausdorff = directed_hausdorff(test_mask_argmax, test_prediction_argmax)[0]\n",
    "  \n",
    "  f1_Score.append(f1)\n",
    "  # hd_score.append(hausdorff)\n",
    "  iou_score.append(IOU_keras.result().numpy())\n",
    "  \n",
    "  print(\"Mean IoU =\", IOU_keras.result().numpy(), f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "10gytFCqBq_w",
    "outputId": "670b538d-c6fd-44e6-b8e0-b78693eb4a74",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(lgg_mask_list, iou_score, f1_Score)),columns =['Image Name', 'IOU', 'F1 Score'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "-abV6tl13Wch",
    "outputId": "333b0c82-826f-4025-b82b-98b6ad1dbce6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req = df['IOU'] > 0.8\n",
    "result = df[req]\n",
    "result = result.sort_values(by = 'IOU', ascending = False)\n",
    "result.to_csv('lgg_IOU_F1.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUAwdUYsjfkz"
   },
   "source": [
    "### **5. Saving the generated Masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cbV2i6CkWND"
   },
   "outputs": [],
   "source": [
    "for i in range(len(lgg_mask_list)):\n",
    "  print(i)\n",
    "  test_img = np.load(lgg_img_dir+lgg_img_list[i])\n",
    "  test_mask = np.load(lgg_mask_dir+lgg_mask_list[i])\n",
    "  # test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "  test_img_input = np.expand_dims(test_img, axis=0)\n",
    "  test_prediction = model.predict(test_img_input)\n",
    "  test_prediction = test_prediction[0]\n",
    "  # test_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]\n",
    "\n",
    "  np.save('/content/drive/MyDrive/Brain Tumor Major Project/Semantic Segmented 3D Dataset/LGG/'+lgg_mask_list[i],test_prediction)\n",
    "\n",
    "  n_slice = 55\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plt.subplot(231)\n",
    "  plt.title('Testing Image')\n",
    "  plt.imshow(test_img[:,:,n_slice], cmap='gray')\n",
    "  plt.subplot(232)\n",
    "  plt.title('Testing Label')\n",
    "  plt.imshow(test_mask[:,:,n_slice,0])\n",
    "  plt.subplot(233)\n",
    "  plt.title('Prediction on test image')\n",
    "  plt.imshow(test_prediction[:,:, n_slice,0])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27sswuW6RDBG"
   },
   "source": [
    "\n",
    "# **Imposition of Generated Masks on MRI Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWuYU-qliauc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH3_jKf2ia2D"
   },
   "outputs": [],
   "source": [
    "hgg_denoised_img_path = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised Image Dataset/HGG/'\n",
    "hgg_mask_path = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Semantic Segmented 3D Dataset/HGG/'\n",
    "hgg_mask_imposed_img_path = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Mask Imposed Image Dataset/HGG/'\n",
    "hgg_img_list=os.listdir(hgg_denoised_img_path)\n",
    "hgg_mask_list = os.listdir(hgg_mask_path)\n",
    "\n",
    "lgg_denoised_img_path = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Denoised Image Dataset/LGG/'\n",
    "lgg_mask_path = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Semantic Segmented 3D Dataset/LGG/'\n",
    "lgg_mask_imposed_img_path = '/content/drive/MyDrive/Brain Tumor Major Project/Denoised Classification/Mask Imposed Image Dataset/LGG/'\n",
    "lgg_img_list=os.listdir(lgg_denoised_img_path)\n",
    "lgg_mask_list = os.listdir(lgg_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89kqTOUzifg0"
   },
   "outputs": [],
   "source": [
    "def impose_mask(img_path,img_list,mask_path,mask_list,destination_path):\n",
    "  for i in range(len(img_list)):\n",
    "    img = np.load(img_path+img_list[i])\n",
    "    mask = np.load(mask_path+mask_list[i])\n",
    "\n",
    "    mask = np.argmax(mask, axis=3)\n",
    "    idx = np.where(mask!=0)\n",
    "    mask[idx]=1\n",
    "    \n",
    "    mask_imposed_img = img * mask\n",
    "\n",
    "    np.save(destination_path+'masked_img_'+img_list[i],mask_imposed_img)  \n",
    "\n",
    "    if i in [4,29,37,45]:\n",
    "      fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "      ax0 = fig.add_subplot(1, 5, 1)\n",
    "      ax0.imshow(img[:, 55, :], cmap='gray')\n",
    "      ax0.set_title('Original Image')\n",
    "\n",
    "      ax1 = fig.add_subplot(1, 5, 2)\n",
    "      ax1.imshow(mask_imposed_img[:, 55, :], cmap='gray')\n",
    "      ax1.set_title('Mask Imposed Image')\n",
    "\n",
    "      ax2 = fig.add_subplot(1, 5, 3)\n",
    "      ax2.imshow(mask[:, 55, :], cmap='gray')\n",
    "      ax2.set_title('Mask')\n",
    "\n",
    "      fig.subplots_adjust(wspace=0.3)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "wHJpM5qgifjU",
    "outputId": "264fd4db-6a24-4fb0-e78d-06dac2a61d8c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impose_mask(hgg_denoised_img_path, hgg_img_list, hgg_mask_path, hgg_mask_list, hgg_mask_imposed_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "vYXHk0UbGPhh",
    "outputId": "0a410c2a-455b-4194-9275-62d2807b0cb9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impose_mask(lgg_denoised_img_path, lgg_img_list, lgg_mask_path, lgg_mask_list, lgg_mask_imposed_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGG_image_paths = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/HGG'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname,filename)\n",
    "        HGG_image_paths.append(file_path)\n",
    "        #print(os.path.join(file_path))\n",
    "print(len(HGG_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGG_image_paths = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/LGG'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname,filename)\n",
    "        LGG_image_paths.append(file_path)\n",
    "        #print(os.path.join(file_path))\n",
    "print(len(LGG_image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "There are 46 images in the HGG category and 48 images in the LGG category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_npy = '/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/HGG/masked_img_denoised_image_0.npy'\n",
    "data_npy = np.load(file_path_npy)\n",
    "data_npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = int(np.ceil(np.sqrt(data_npy.shape[2])))\n",
    "num_cols = int(np.ceil(data_npy.shape[2] / num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/HGG_slices',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/LGG_slices',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/HGG'\n",
    "output_dir = '/kaggle/working/HGG_slices'\n",
    "\n",
    "# Iterate over all .npy files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Load the 3D numpy array from the file\n",
    "        path = os.path.join(input_dir, filename)\n",
    "        #print(path)\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Create a new subdirectory for this image\n",
    "        image_dir = os.path.join(output_dir, os.path.splitext(filename)[0])\n",
    "        #print(image_dir)\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # Save each 2D slice of the 3D numpy array as a separate PNG file\n",
    "        for i in range(data.shape[2]):\n",
    "            slice_path = os.path.join(image_dir, f'slice_{i:03d}.png')\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            plt.imsave(slice_path, data[:, :, i], cmap='gray')\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/brats-2020-denoised-data/Mask Imposed Image Dataset/LGG'\n",
    "output_dir = '/kaggle/working/LGG_slices'\n",
    "\n",
    "# Iterate over all .npy files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Load the 3D numpy array from the file\n",
    "        path = os.path.join(input_dir, filename)\n",
    "        #print(path)\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Create a new subdirectory for this image\n",
    "        image_dir = os.path.join(output_dir, os.path.splitext(filename)[0])\n",
    "        #print(image_dir)\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # Save each 2D slice of the 3D numpy array as a separate PNG file\n",
    "        for i in range(data.shape[2]):\n",
    "            slice_path = os.path.join(image_dir, f'slice_{i:03d}.png')\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "            plt.imsave(slice_path, data[:, :, i], cmap='gray')\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copying folders to delete all black slices and also having backup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_folder(src_folder, dst_folder):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    for item in os.listdir(src_folder):\n",
    "        src_item = os.path.join(src_folder, item)\n",
    "        dst_item = os.path.join(dst_folder, item)\n",
    "        if os.path.isdir(src_item):\n",
    "            copy_folder(src_item, dst_item)\n",
    "        else:\n",
    "            shutil.copy2(src_item, dst_item)\n",
    "\n",
    "copy_folder(\"/kaggle/working/LGG_slices\", \"/kaggle/working/LGG_slices_copy\")\n",
    "copy_folder(\"/kaggle/working/HGG_slices\", \"/kaggle/working/HGG_slices_copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working in LGG_slices_copy and HGG_slices_copy folders to delete all black images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def delete_black_images(folder_path):\n",
    "    for subdir, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                pixels = img.load()\n",
    "                width, height = img.size\n",
    "                for x in range(width):\n",
    "                    for y in range(height):\n",
    "                        if pixels[x, y] != (0, 0, 0):\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "                    break\n",
    "                else:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Deleted {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "delete_black_images(\"/kaggle/working/LGG_slices_copy\")\n",
    "delete_black_images(\"/kaggle/working/HGG_slices_copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "image_path = \"/kaggle/working/LGG_slices_copy/masked_img_denoised_image_64/slice_033.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert image to grayscale\n",
    "image = image.convert(\"L\")\n",
    "\n",
    "# Get histogram data\n",
    "histogram = image.histogram()\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(histogram, bins=256, range=(0, 256), color='black')\n",
    "plt.title(\"Image Histogram\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "image_path = \"/kaggle/working/LGG_slices_copy/masked_img_denoised_image_64/slice_004.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert image to grayscale\n",
    "image = image.convert(\"L\")\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "pixels = np.asarray(image) / 255.0\n",
    "\n",
    "# Create heatmap using viridis colormap\n",
    "heatmap = plt.cm.viridis(pixels)\n",
    "\n",
    "if np.unique(pixels).size == 1:\n",
    "    print(\"The heatmap has no color variations.\")\n",
    "else:\n",
    "    print(\"The heatmap has color variations.\")\n",
    "\n",
    "# Plot heatmap\n",
    "plt.imshow(heatmap)\n",
    "plt.title(\"Image Heatmap\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_black_images_heatmap(folder_path):\n",
    "    for subdir, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(subdir, file)\n",
    "            image = Image.open(image_path)\n",
    "            image = image.convert(\"L\")\n",
    "            pixels = np.asarray(image) / 255.0\n",
    "            if np.unique(pixels).size == 1:\n",
    "                print(f\"Deleted {image_path}\")\n",
    "                os.remove(image_path)\n",
    "\n",
    "delete_black_images_heatmap(\"/kaggle/working/LGG_slices_copy\")\n",
    "delete_black_images_heatmap(\"/kaggle/working/HGG_slices_copy\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Get number of images in folder\n",
    "folder_path = \"/kaggle/working/LGG_slices_copy/masked_img_denoised_image_64\"\n",
    "num_images = len(os.listdir(folder_path))\n",
    "\n",
    "# Calculate number of rows and columns\n",
    "num_plots = math.ceil(math.sqrt(num_images))\n",
    "num_cols = num_plots\n",
    "num_rows = num_plots\n",
    "\n",
    "# Set figure size\n",
    "fig_width = 10\n",
    "fig_height = 10\n",
    "\n",
    "# Create figure and axes\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(fig_width, fig_height))\n",
    "\n",
    "# Flatten axes array to make it easier to iterate over\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over all images in folder\n",
    "for i, file in enumerate(os.listdir(folder_path)):\n",
    "    if i >= num_cols * num_rows:\n",
    "        break\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    img = Image.open(file_path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "# Show figure\n",
    "plt.tight_layout()\n",
    "plot_path = \"/kaggle/working/remove_all_black_slices.png\"\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All black images have been deleted now. Copying folders to do data augmentation and also have backup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_folder(src_folder, dst_folder):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    for item in os.listdir(src_folder):\n",
    "        src_item = os.path.join(src_folder, item)\n",
    "        dst_item = os.path.join(dst_folder, item)\n",
    "        if os.path.isdir(src_item):\n",
    "            copy_folder(src_item, dst_item)\n",
    "        else:\n",
    "            shutil.copy2(src_item, dst_item)\n",
    "\n",
    "copy_folder(\"/kaggle/working/LGG_slices_copy\", \"/kaggle/working/LGG_slices_augmented\")\n",
    "copy_folder(\"/kaggle/working/HGG_slices_copy\", \"/kaggle/working/HGG_slices_augmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Peforming data augmentation now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Set up data augmentation parameters\n",
    "rotation_angles = [30, 60, 90]\n",
    "flip_axes = [0, 1, -1]\n",
    "\n",
    "# Iterate over all subfolders in folder\n",
    "folder_path = \"/kaggle/working/LGG_slices_augmented\"\n",
    "for subfolder in os.listdir(folder_path):\n",
    "    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "    if not os.path.isdir(subfolder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate over all images in subfolder\n",
    "    for file in os.listdir(subfolder_path):\n",
    "        file_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Load image\n",
    "        img = cv2.imread(file_path)\n",
    "\n",
    "        # Perform data augmentation\n",
    "        for angle in rotation_angles:\n",
    "            rotated = Image.fromarray(img).rotate(angle)\n",
    "            rotated.save(file_path[:-4] + f\"_rotated{angle}.png\")\n",
    "\n",
    "        for axis in flip_axes:\n",
    "            flipped = cv2.flip(img, axis)\n",
    "            cv2.imwrite(file_path[:-4] + f\"_flipped{axis}.png\", flipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Set up data augmentation parameters\n",
    "rotation_angles = [30, 60, 90]\n",
    "flip_axes = [0, 1, -1]\n",
    "\n",
    "# Iterate over all subfolders in folder\n",
    "folder_path = \"/kaggle/working/HGG_slices_augmented\"\n",
    "for subfolder in os.listdir(folder_path):\n",
    "    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "    if not os.path.isdir(subfolder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate over all images in subfolder\n",
    "    for file in os.listdir(subfolder_path):\n",
    "        file_path = os.path.join(subfolder_path, file)\n",
    "\n",
    "        # Load image\n",
    "        img = cv2.imread(file_path)\n",
    "\n",
    "        # Perform data augmentation\n",
    "        for angle in rotation_angles:\n",
    "            rotated = Image.fromarray(img).rotate(angle)\n",
    "            rotated.save(file_path[:-4] + f\"_rotated{angle}.png\")\n",
    "\n",
    "        for axis in flip_axes:\n",
    "            flipped = cv2.flip(img, axis)\n",
    "            cv2.imwrite(file_path[:-4] + f\"_flipped{axis}.png\", flipped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving a plot of augmented slices now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/kaggle/working/HGG_slices_augmented\"\n",
    "subdirectories = [f.path for f in os.scandir(directory_path) if f.is_dir()]\n",
    "\n",
    "# Print list of subdirectories\n",
    "print(subdirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Get number of images in folder\n",
    "folder_path = \"/kaggle/working/HGG_slices_augmented/masked_img_denoised_image_25\"\n",
    "num_images = len(os.listdir(folder_path))\n",
    "\n",
    "# Calculate number of rows and columns\n",
    "num_plots = math.ceil(math.sqrt(num_images))\n",
    "num_cols = 10\n",
    "num_rows = num_plots\n",
    "\n",
    "# Set figure size\n",
    "fig_width = 10\n",
    "fig_height = 10\n",
    "\n",
    "# Create figure and axes\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(fig_width, fig_height))\n",
    "\n",
    "# Flatten axes array to make it easier to iterate over\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over all images in folder\n",
    "for i, file in enumerate(os.listdir(folder_path)):\n",
    "    if i >= num_cols * num_rows:\n",
    "        break\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    img = Image.open(file_path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "# Show figure\n",
    "plt.tight_layout()\n",
    "plot_path = \"/kaggle/working/augmented_slices_HGG.png\"\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
